[![news](/pics/header.png)](/vids/News_vid.mp4?raw=true)  
 
#### Table of Contents  

[Project Roadmap](#project-roadmap )    
[Project Overview](#project-overview)  
[Resources](#resources)  
[Technology](#technology)  
[Objectives](#objectives)  
[Summary](#summary)  
[Dashboard](#dashboard)  
[Presentation](#presentation)  
[Recommendation](#recommendation)  
[Limitations](#limitations)  
[Sources](#sources)  
[Communication Protocols](#communication-protocols)  
<br/>
<br/>
<br/>
<br/>

## Project Roadmap  
The project roadmap and description of all the project deliverables can be found in [Deliverables.md](/Deliverables.md)  
<br/>
<br/>
<br/>
<br/>

## Project Overview    
#### Nearly 700,000 people left California last year
###### Despite roughly 500,000 people coming to the Golden State in 2018, census data shows more people left California than moved in.
##### CALIFORNIA, USA — In 2018, nearly 700,000 people decided to pack their bags and leave the California life behind.

##### **By contrast, there were only 501,000 people who decided to follow the California dream and set up camp in the state. With 691,000 people leaving the Golden State for another state, California was in the negative as far as net population change.**

##### The exodus from California also led among other states. Only the numbers for Texas, Florida, and New York came close.

##### **Texas lost 462,000; New York lost 458,000; and Florida lost 470,000.**

##### According to [the Census data](https://www.census.gov/data/tables/time-series/demo/geographic-mobility/state-to-state-migration.html), most Californians found themselves heading to Texas, Arizona, Washington, Nevada, and Oregon.  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**Texas** - 86,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**Arizona** - 68,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**Washington** - 55,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**Nevada** - 50,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**Oregon** - 43,000  

##### While California led in people leaving the state in 2018, it came in third for the number of people who moved in. The state was behind Florida, who had 587,000, and Texas, who saw 563,000 move in.

##### **Census data also showed that the number of people leaving California has steadily increased since 2011.**  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**2018** - 691,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**2017** - 661,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**2016** - 657,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**2015** - 643,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**2014** - 593,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**2013** - 581,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**2012** - 566,000  
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;**2011** - 562,000  

##### A [2018 study by the California Legislative Analyst's Office](https://lao.ca.gov/laoecontax/article/detail/265) revealed that more than a million people left California - spread out over a decade - as opposed to those who moved here from other states.  

##### The study said high taxes, cost of living, and affordable housing were among the main reasons why people were leaving.  

##### A [recent study by UC Berkeley](https://escholarship.org/uc/item/96j2704t) made similar findings with voters. According to the poll, roughly half of the state's voters have considered leaving California.  

##### The main reason was the high cost of housing, but high taxes and political culture were also big reasons voters considered leaving.  

###### &nbsp; &nbsp; &nbsp; &nbsp;  Author: **Eric Escalante**  
###### &nbsp; &nbsp; &nbsp; &nbsp;  Published: **5:30 PM PST November 5, 2019**  
###### &nbsp; &nbsp; &nbsp; &nbsp;  Updated: **12:38 PM PST November 11, 2019**  
###### &nbsp; &nbsp; &nbsp; &nbsp;  Full article can be found at [abc10.com](https://www.abc10.com/article/news/local/california/691000-leave-california/103-e02662aa-dfae-46b2-b94a-f20158053e60)  
<br/>
<br/>
<br/>
<br/>  

### **Reason the topic was selected**  
##### **There are many articles written, like this one, about Califorian's leaving due to the high cost of living. The reason this topic was selected, with our group living in California, it's personal.**  

As a broad generalization, most people can afford to purchase a house worth about **3X** their **total (gross) annual income**, assuming a **20% down** payment and a moderate amount of other long-term debts, such as car or student loan payments. This best practice can be found at [mymoneyblog.com](https://www.mymoneyblog.com/4-different-rules-of-thumb-for-how-much-house-you-can-afford.html). As there are many similar "Best Practices" in home buying, We would like to keep a consistancy throughout the analysis and use this one, three times total annual income. The consistancy will make the analysis meaningful. 

With the best pracice in mind and the median price of homes currently, as of 02/13/20, listed in San Bernardino County is **$350,000**, according to [zillow.com](https://www.zillow.com/san-bernardino-county-ca/home-values/), a single gross income of **$116,666.67** would be needed to purchase a **median price** home in **San Bernardino County**.  

Although, that number is flabbergasting enough, it fails when compared to surrounding California counties.These counties the median home prices are, easily, **doubled**.  Meaning, the gross annual income would, also, have to **double**.  
Pricing can be seen on [laalmanac.com](http://www.laalmanac.com/economy/ec37.php)  
<br/>
<br/>
<br/>
<br/>  

### **Questions the team hopes to answer with the data**  
##### **We would like to perform analysis on the cost of housing in California that included**:  
- Median Home Price
- Median Household Income  

##### **Questions the team hopes to answer with the data is:**  
- What are the California median household prices in California expected to be in the next five years?  
- What are the California median household prices in California expected to be in the next ten years?  
- Based on the ["Best Practices"](https://www.mymoneyblog.com/4-different-rules-of-thumb-for-how-much-house-you-can-afford.html) in home buying, how much income would be needed to live in a median priced home in California at that time.  
- What are the top 5 states Californians are moving to?  
- How does California housing cost compare to those 5 states?  

##### **After our analysis, we hope to answer:**
- Is it time to leave California?  
<br/>
<br/>
<br/>
<br/>

## Resources  
- **Data Source:** [2010_data](/Resources/data/2010_data.csv) | [2011_data](/Resources/data/2011_data.csv) | [2012_data](/Resources/data/2012_data.csv) | [2013_data](/Resources/data/2013_data.csv) | [2014_data](/Resources/data/2014_data.csv) | [2015_data](/Resources/data/2015_data.csv) | [2016_data](/Resources/data/2016_data.csv) | [2017_data](/Resources/data/2017_data.csv) | [2018_data](/Resources/data/2018_data.csv) | [population_data](/Resources/data/population_data.csv) | [migration_2010](/Resources/data/migration_2010.csv) | [migration_2011](/Resources/data/migration_2011.csv) | [migration_2012](/Resources/data/migration_2012.csv) | [migration_2013](/Resources/data/migration_2013.csv) | [migration_2014](/Resources/data/migration_2014.csv) | [migration_2015](/Resources/data/migration_2015.csv) | [migration_2016](/Resources/data/migration_2016.csv) | [migration_2017](/Resources/data/migration_2017.csv) | [migration_2018](/Resources/data/migration_2018.csv) |  [zillow_data](/Resources/data/zillow_data.csv)  
<br/>
<br/>
<br/>
<br/>  

## Technology
- **Software:** Jupyter Notebook, pgAdmin,   
- **Languages:** Python, JSON, SQL  
- **Dependencies:** Pandas, Matplotlib, SciPy  
- **Algorithms:**  
<br/>
<br/>
<br/>
<br/>  

## Objectives   
- Import, analyze, clean, and preprocess a “real-world” classification dataset.
- Select, design, and train a binary classification model of our choosing.
- Optimize model training and input data to achieve desired model performance.  
<br/>
<br/>
<br/>
<br/>  

## Summary  
- Description of the data exploration phase of the project  
  - Data selection  
  - Data processing  
  - Data transformation
- Machine Learning Model   
- Database Integration  
- Description of the analysis phase of the project  
<br/>
<br/>
<br/>
<br/>  

## Description of the data exploration phase of the project  
### **Data Selection**  
**Data selection entails making good choices about which data will be used. Consider what data is available, what data is missing, and what data can be removed.**  

The first roadblock our team encountered was lack of data, from our data selection, for our origional machine learning concept. Our first concept involved extracting data for our individual counties to compare against each other, then choose one county from another state to compare against our indivual results. Although, there is robust amount of data available through the [data.census.gov](https://data.census.gov) website, after filtering what was needed for our analysis, the amount of data remaining was not enough to provide a meaningful analysis. To overcome this obsticle we decided to broaden our analysis from four counties to all states in the U.S.. California is, now, our targeted data to compare against all the other states.  

##### **What data is available?**  
First, we account for the data we have. We use the **columns method** and output the columns. Our output of column titles does **not** let us know what data we have. The output shows codes.  

<img align="left" width="700" src="/pics/columns.png"><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>  

Scrolling back to the dataframe we can see the first row has the column description.  

<img align="left" width="700" src="/pics/df.png"><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>  

We refered back to the Excel file and expanded the cells to get the full description of the column values.  

<img align="left" width="700" src="/pics/excel.png"><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>  

##### **What type of data is available?**  
Using the **dtypes method**, we confirm the data type, which also will alert us if anything should be changed in the next step. All the columns we plan to use in our model must contain a numerical data type. Our data is all **Objects** and needs to be converted to a **numeric** data type.  

<img align="left" width="700" src="/pics/dtypes.png"><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>  

##### **What data is missing?**  
Next, we see if any data is missing. Unsupervised learning models can’t handle missing data. If we try to run a model on a dataset with missing data, we’ll get an error. Pandas has the **isnull() method** to check for missing values. We loop through each column, check if there are null values, sum them up, and print out a readable total. We can, easily, read through our output and see there are **no** null values in our dataset. 

<img align="left" width="700" src="/pics/null_values.png"><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>  

##### **What data can be removed?**  
We have begun to explore the data and have taken a look at null values. Next, we determine if the data can be removed. We consider: Are there string columns that we can’t use? Are there columns with excessive null data points? Was our decision to handle missing values to just remove them?  

In our dataset, there are **no** rows that have null data points. Using the **duplicated().sum() method**, we, also, saw our dataset did **not** have duplicates.  

<img align="left" width="700" src="/pics/duplicate.png"><br/>
<br/>
<br/>  

With uncertainty of what housing data would be of value for our analysis, we went the safe route and only removed the **Margin of Error!!VALUE!!** columns. Those columns represented a margin of error for each statistic given. We felt,they would not serve a purpose for our, specific, analysis. Maybe, a complimentary analysis giving a margin of error for our analysis, at a later time. For now, we used **pandas.DataFrame.filter** to remove those columns from our dataframe.  

<img align="left" width="700" src="/pics/filter.png"><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>  

### Data Preprocessing  
**Data processing involves organizing the data by formatting, cleaning, and sampling it. For data processing, the focus is on making sure the data is set up for the unsupervised learning model, which requires the following:**
- Null values are handled.
- Only numerical data is used.
- Values are scaled. In other words, data has been manipulated to ensure that the variance between the numbers won’t skew results.  

##### **Is the data in a format that can be passed into an unsupervised learning model?**  
We saw that all our data had the incorrect type for each column. We had to use [pandas.to_numeric](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html) to convert our arguments to a numeric type. Also, we know that our model can’t have strings passed into it. The only string value left is the name of the states. 

In our dataset on states housing cost, The scale for Median Income and Median Home Value is much larger than all the other values in the dataset. We adjusted this format by dividing by 1,000 to rescale those data points.  
<br/>
<br/>
<br/>
<br/>  

### **Data Transformation**  
**Data transformation involves thinking about the future. More times than not, there will be new data coming into our data storage, with three people working on different types of data analysis. We want to make sure that whoever wants to use the data in the future can do so.**  

##### **Can I quickly hand off this data for others to use?**  
The data now needs to be transformed back into a more user-friendly format. We converted the final products into common data type(CSV) files. With our data being cleaned and processed, it is ready to be converted to a readable format for future use.  

We had to perform all these steps on all our datasets. We kept the procees consist, not only, for us to be able to easily concatenate the years, but to have a meaningul analysis.  

The migration datsets were, also, done similarly. The most predominant change was having to add a line of code to remove the commas from the number values in order to be able to make them floats.  
<br/>
<br/>
<br/>
<br/>

### Machine Learning Model
**Description of feature engineering and the feature selection, including the team’s decision-making process**  
Machine learning is the use of statistical algorithms to perform tasks such as learning from data patterns and making predictions. There are many different models; a mathematical representation of something that happens in the real world. Machine learning can be divided into three learning categories: supervised, unsupervised, and deep.  

We decided to do **supervised learning**, which deals with labeled data. This supervised learning will be to predict, based on data from the census, whether it's time to leave California.  
<br/>
<br/>

**Description of how data was split into training and testing sets**  
The model uses the training dataset to learn from it. It then uses the testing dataset to assess its performance. If you use your entire dataset to train the model, you won’t know how well the model will perform when it encounters unseen data. That is why it’s important to set aside a portion of your dataset to evaluate your model.  
<br/>
<br/>

**Explanation of model choice, including limitations and benefits**  
We chose to use a random forest classifier. Random forest classifiers are a type of ensemble learning model that combines multiple smaller models into a more robust and accurate model. Random forest models use a number of weak learner algorithms (decision trees) and combine their output to make a final classification (or regression) decision.  

Benifits to us using a random forest model are both output and feature selection are easy to interpret, and they can easily handle outliers and nonlinear data.  

Limitations to us using a random forest model are, random forest models will only handle tabular data, so data such as images or natural language data cannot be used in a random forest without heavy modifications to the data.  
<br/>
<br/>

**Explanation of changes in model choice (if changes occurred between the Segment 2 and Segment 3 deliverables)**  
<br/>
<br/>

**Description of how the model was trained (or retrained if the team used an existing model)**  
In this section, we used Scikit-learn’s StandardScaler module to scale data. The model -> fit -> predict/transform workflow is also used when scaling data. The standard scaler standardizes the data. This means, all our numerical columns will now have a mean of 0 and a standard deviation of 1, reducing the likelihood that large values will unduly influence our model.  
<br/>
<br/>

**Description and explanation of model’s confusion matrix, including final accuracy score**  
<img align="left" width="900" src="/pics/confusion_matrix.png"><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

### **Models’ performance**  
**The results show that:**  
- Out of **113** good housing cost (Actual 0), **112** were predicted to be good (Predicted 0), which we call true positives.  
- Out of **113** good housing cost (Actual 0), **1** was predicted to be bad (Predicted 1), which is considered a false negative. 
- Out of **4** bad housing cost (Actual 1), **2** was predicted to be good (Predicted 0) and are considered false positives.  
- Out of **4** bad housing cost (Actual 1), **2** were predicted to be bad (Predicted 1) and are considered true negatives.  
<br/>
<br/>  

##### **Precision**  
Precision is the measure of how reliable a positive classification is. From our results, the precision for the good housing cost can be determined by the ratio **TP/(TP + FP)**, which is **112/(112 + 2) = .9825**. The precision for the bad housing cost can be determined as follows: **2/(2 + 1) = .6667**. A low precision is indicative of a large number of false positives—of the 3 housing cost we predicted to be bad housing cost,  1 was actually a good housing cost.
<br/>
<br/>  

##### **Recall scores**  
Recall is the ability of the classifier to find all the positive samples. It can be determined by the ratio: TP/(TP + FN), or  for the good housing cost **112/(112 + 1) = .9912** and for the bad housing cost **2/(2 + 2) = .5**. A low recall is indicative of a large number of false negatives.
<br/>
<br/>  

##### **Balanced accuracy score**  
An accuracy score is not always an appropriate or a meaningful performance metric. This program’s accuracy score appears to be great at **0.9744**.
<br/>
<br/>  

##### **F1 score**  
F1 score is a weighted average of the true positive rate (recall) and precision, where the best score is 1.0 and the worst is 0.0.
<br/>
<br/>  

##### **Support**  
Support is the number of actual occurrences of the class in the specified dataset. For our results, there are **113** actual occurrences for the good housing cost and **4** actual occurrences for bad housing cost.
<br/>
<br/>  

##### **Recommendation on the model to use:**  
In summary, this model is good at predicting good housing cost. The model's accuracy of is high at **0.9744**, the precision and F1 score are good enough to state that the model will be good at classifying good housing cost.  
<br/>
<br/>
<br/>
<br/>

**How does the model address the question or problem the team is solving.**  
<br/>
<br/>
<br/>
<br/>

### Description of the analysis phase of the project  
<img align="right" width="500" src="/Data/Line Plot.png"><br/>  
<br/>
<br/>
<br/>
<br/>
Different visualization types serve different purposes. The purpose of our line chart is to display data over time. With Matplotlib set up, we were able to see the rate the top five states Californians were moving to.  
<img align="left" width="700" src="/Data/bar graph_by Year.png"><br/>
<br/>
<br/>
<br/>
<br/>  

A bar chart tells a different visual story than a line chart. There are many benefits to using a bar chart. They’re good at displaying discrete data in distinct columns. 
<img align="right" width="700" src="/Data/bar graph_by Name.png"><br/>  
<br/>
<br/>  

They also tend to be visually strong. In a bar chart, we can clearly see the differences among the groups and the bar color of each group.  
<br/>
<br/>
<br/>
<br/>  
<br/>
<br/>
<br/>
<br/>



### Database Integration  
**Our final segment includes a fully integrated database, with the following features:**
- Stores static data for use during the project
- Interfaces with the project in some format (e.g., scraping updates the database, or database connects to the model)
- Includes at least two tables (or collections if using MongoDB)
- Includes at least one join using the database language (not including any joins in Pandas)
- Includes at least one connection string (using SQLAlchemy or PyMongo)
- Important If you use a SQL database, you must provide your Entity Relationship Diagram (ERD) with relationships.  
<br/>
<img align="center" width="700" src="/pics/sql.png"><br/>
<br/>
<br/>
<br/>
<br/>

## Recommendation
**Recommendation for future analysis**  
<br/>
<br/>
<br/>
<br/>

## Limitations  
**Anything the team would have done differently**  
<br/>
<br/>
<br/>
<br/>

## Dashboard
The dashboard presents a data story that is logical and easy to follow for someone unfamiliar with the topic. It includes all of the following:
- Images from the initial analysis
- Data (images or report) from the machine learning task
- At least one interactive element
- Either the dashboard is published or the submission includes a screen capture video of it in action  
<br/>
<br/>
<br/>
<br/>

## Presentation  
The presentation can be found in [Google Slides](https://docs.google.com/presentation/d/14h7wNLqN1Vh8AVsPMiOpv18YU4jbhMqiKdh0yhPtdns/edit?usp=sharing)  
<br/>
<br/>
<br/>
<br/>

## Sources  
### Description of the source of data  
**All .csv resources for our analysis were downloaded from [data.census.gov](https://data.census.gov) and [www2.census.gov](https://www2.census.gov)**  

Resources for data:  
- [population_data](https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/national/totals/nst-est2019-alldata.csv?#)  
- [2010_data](https://data.census.gov/cedsci/table?g=0100000US.04000.001&y=2010&tid=ACSST1Y2010.S2506&t=Financial%20Characteristics%3AHousing%3AHousing%20Value%20and%20Purchase%20Price%3AIncome%20%28Households,%20Families,%20Individuals%29%3AIncome%20and%20Earnings%3AIncome%20and%20Poverty%3AMortgage%20Costs&vintage=2018&hidePreview=true&moe=false)  
- [2011_data](https://data.census.gov/cedsci/table?g=0100000US.04000.001&y=2011&tid=ACSST1Y2011.S2506&t=Financial%20Characteristics%3AHousing%3AHousing%20Value%20and%20Purchase%20Price%3AIncome%20%28Households,%20Families,%20Individuals%29%3AIncome%20and%20Earnings%3AIncome%20and%20Poverty%3AMortgage%20Costs&vintage=2018&hidePreview=true&moe=false)

- [2012_data](https://data.census.gov/cedsci/table?g=0100000US.04000.001&y=2012&tid=ACSST1Y2012.S2506&=Financial%20Characteristics%3AHousing%3AHousing%20Value%20and%20Purchase%20Price%3AIncome%20%28Households,%20Families,%20Individuals%29%3AIncome%20and%20Earnings%3AIncome%20and%20Poverty%3AMortgage%20Costs&vintage=2018&hidePreview=true&moe=false)

- [2013_data](https://data.census.gov/cedsci/table?g=0100000US.04000.001&y=2013&tid=ACSST1Y2013.S2506&t=Financial%20Characteristics%3AHousing%3AHousing%20Value%20and%20Purchase%20Price%3AIncome%20%28Households,%20Families,%20Individuals%29%3AIncome%20and%20Earnings%3AIncome%20and%20Poverty%3AMortgage%20Costs&vintage=2018&hidePreview=true&moe=false)

- [2014_data](https://data.census.gov/cedsci/table?g=0100000US.04000.001&y=2014&tid=ACSST1Y2014.S2506&t=Financial%20Characteristics%3AHousing%3AHousing%20Value%20and%20Purchase%20Price%3AIncome%20%28Households,%20Families,%20Individuals%29%3AIncome%20and%20Earnings%3AIncome%20and%20Poverty%3AMortgage%20Costs&vintage=2018&hidePreview=true&moe=false)

- [2015_data](https://data.census.gov/cedsci/table?g=0100000US.04000.001&y=2015&tid=ACSST1Y2015.S2506&t=Financial%20Characteristics%3AHousing%3AHousing%20Value%20and%20Purchase%20Price%3AIncome%20%28Households,%20Families,%20Individuals%29%3AIncome%20and%20Earnings%3AIncome%20and%20Poverty%3AMortgage%20Costs&vintage=2018&hidePreview=true&moe=false)

- [2016_data](https://data.census.gov/cedsci/table?g=0100000US.04000.001&y=2016&tid=ACSST1Y2016.S2506&t=Financial%20Characteristics%3AHousing%3AHousing%20Value%20and%20Purchase%20Price%3AIncome%20%28Households,%20Families,%20Individuals%29%3AIncome%20and%20Earnings%3AIncome%20and%20Poverty%3AMortgage%20Costs&vintage=2018&hidePreview=true&moe=false)

- [2017_data](https://data.census.gov/cedsci/table?g=0100000US.04000.001&y=2017&tid=ACSST1Y2017.S2506&t=Financial%20Characteristics%3AHousing%3AHousing%20Value%20and%20Purchase%20Price%3AIncome%20%28Households,%20Families,%20Individuals%29%3AIncome%20and%20Earnings%3AIncome%20and%20Poverty%3AMortgage%20Costs&vintage=2018&hidePreview=true&moe=false)

- [2018_data](https://data.census.gov/cedsci/table?g=0100000US.04000.001&y=2018&tid=ACSST1Y2018.S2506&t=Financial%20Characteristics%3AHousing%3AHousing%20Value%20and%20Purchase%20Price%3AIncome%20%28Households,%20Families,%20Individuals%29%3AIncome%20and%20Earnings%3AIncome%20and%20Poverty%3AMortgage%20Costs&vintage=2018&hidePreview=true&moe=false)  

- [migration_2010](https://www2.census.gov/programs-surveys/demo/tables/geographic-mobility/2010/state-to-state-migration/state_to_state_migrations_table_2010.xls)  
- [migration_2011](https://www2.census.gov/programs-surveys/demo/tables/geographic-mobility/2012/state-to-state-migration/state_to_state_migrations_table_2012.xls)  
- [migration_2012](https://www2.census.gov/programs-surveys/demo/tables/geographic-mobility/2012/state-to-state-migration/state_to_state_migrations_table_2012.xls)
- [migration_2013](https://www2.census.gov/programs-surveys/demo/tables/geographic-mobility/2013/state-to-state-migration/state_to_state_migrations_table_2013.xls)
- [migration_2014](https://www2.census.gov/programs-surveys/demo/tables/geographic-mobility/2014/state-to-state-migration/State_to_State_Migrations_Table_2014.xls)
- [migration_2015](https://www2.census.gov/programs-surveys/demo/tables/geographic-mobility/2015/state-to-state-migration/State_to_State_Migrations_Table_2015.xls)
- [migration_2016](https://www2.census.gov/programs-surveys/demo/tables/geographic-mobility/2016/state-to-state-migration/State_to_State_Migrations_Table_2016.xls)
- [migration_2017](https://www2.census.gov/programs-surveys/demo/tables/geographic-mobility/2017/state-to-state-migration/State_to_State_Migrations_Table_2017.xls)
- [migration_2018](https://www2.census.gov/programs-surveys/demo/tables/geographic-mobility/2018/state-to-state-migration/State_to_State_Migrations_Table_2018.xls)  

### DBD created at :
- [quickdatabasediagrams.com](https://www.quickdatabasediagrams.com/)


### Description of visual sources:
**README.md video** was created with clips from: 
- [California faces housing 'crisis' amid extremely high rents](https://www.youtube.com/watch?v=kJH4wSW_X5A)
- [California housing crisis reaches boiling point](https://www.youtube.com/watch?v=Q4Zq5NmoWoM)
- [Can Big Tech Curb A Housing Crisis It Helped Cause](https://www.youtube.com/watch?v=e-cT0gQQsiw)
- [Goodbye, California! Longtime residents fleeing rising housing cost](https://www.youtube.com/watch?v=Q4t7GlCs2IY)  

**README.md header picture** was found at:
- [zerohedge.com](https://www.zerohedge.com/political/conservative-californians-leaving-droves-america-first-law-and-order-red-states)  

**Code pictures** were screenshots of:  
- [.ipynb]()  
- [.ipynb]()  
- [.ipynb]()  
<br/>
<br/>
<br/>
<br/>

## Communication Protocols  
It is important to establish a communication protocol. We created direct messages for only team members in Slack at [final-project-jas](https://ucbdatasept19.slack.com/archives/CTXNA5K5G) and exchanged cell phone numbers where we created a group-text.  

- Instant commumnication will be done via text  
- Ideas and links will be done via Slack  
- Meetups will be held via Zoom  

In an emergency we will inform our group through our group-text and reach out to the staff by direct conversation in Slack.
